{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations=glob.glob('data/OPP-115/annotations/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_list=[]\n",
    "for file in annotations:\n",
    "    annotations_list.append(pd.read_csv(file, header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot=pd.concat(annotations_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot.columns = ['annotation_ID', 'batch_ID', 'annotator_ID', 'policy_ID', 'segment_ID','category_name',\n",
    "            'attribute_value_pairs','date','policy_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot['dict'] = annot.attribute_value_pairs.apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_ID</th>\n",
       "      <th>batch_ID</th>\n",
       "      <th>annotator_ID</th>\n",
       "      <th>policy_ID</th>\n",
       "      <th>segment_ID</th>\n",
       "      <th>category_name</th>\n",
       "      <th>attribute_value_pairs</th>\n",
       "      <th>date</th>\n",
       "      <th>policy_URL</th>\n",
       "      <th>dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13160</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>{\"Other Type\": {\"endIndexInSegment\": 575, \"sta...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Other Type': {'endIndexInSegment': 575, 'sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13161</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>1</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>{\"Collection Mode\": {\"endIndexInSegment\": -1, ...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Collection Mode': {'endIndexInSegment': -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13162</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>1</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>{\"Collection Mode\": {\"endIndexInSegment\": -1, ...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Collection Mode': {'endIndexInSegment': -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13163</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>1</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>{\"Collection Mode\": {\"endIndexInSegment\": -1, ...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Collection Mode': {'endIndexInSegment': -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13164</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>1</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>{\"Collection Mode\": {\"endIndexInSegment\": -1, ...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Collection Mode': {'endIndexInSegment': -1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation_ID                                       batch_ID  annotator_ID  \\\n",
       "0          13160  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "1          13161  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "2          13162  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "3          13163  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "4          13164  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "\n",
       "   policy_ID  segment_ID               category_name  \\\n",
       "0       3828           0                       Other   \n",
       "1       3828           1  First Party Collection/Use   \n",
       "2       3828           1  First Party Collection/Use   \n",
       "3       3828           1  First Party Collection/Use   \n",
       "4       3828           1  First Party Collection/Use   \n",
       "\n",
       "                               attribute_value_pairs    date  \\\n",
       "0  {\"Other Type\": {\"endIndexInSegment\": 575, \"sta...  5/7/15   \n",
       "1  {\"Collection Mode\": {\"endIndexInSegment\": -1, ...  5/7/15   \n",
       "2  {\"Collection Mode\": {\"endIndexInSegment\": -1, ...  5/7/15   \n",
       "3  {\"Collection Mode\": {\"endIndexInSegment\": -1, ...  5/7/15   \n",
       "4  {\"Collection Mode\": {\"endIndexInSegment\": -1, ...  5/7/15   \n",
       "\n",
       "                                          policy_URL  \\\n",
       "0  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "1  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "2  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "3  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "4  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "\n",
       "                                                dict  \n",
       "0  {'Other Type': {'endIndexInSegment': 575, 'sta...  \n",
       "1  {'Collection Mode': {'endIndexInSegment': -1, ...  \n",
       "2  {'Collection Mode': {'endIndexInSegment': -1, ...  \n",
       "3  {'Collection Mode': {'endIndexInSegment': -1, ...  \n",
       "4  {'Collection Mode': {'endIndexInSegment': -1, ...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in annot['dict']:\n",
    "    for key, value in x.items():\n",
    "        value.pop('endIndexInSegment', None)\n",
    "        value.pop('startIndexInSegment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[]\n",
    "category=[]\n",
    "subcat=[]\n",
    "label=[]\n",
    "counter=0\n",
    "for i,x in enumerate(annot['dict']):\n",
    "    for key, value in x.items():\n",
    "        subcat.append(key)\n",
    "        if value.get('selectedText')==None:\n",
    "            text.append('noSelectedText')\n",
    "        else:\n",
    "            text.append(value.get('selectedText'))  \n",
    "        category.append(annot['category_name'][i])\n",
    "        for k, v in value.items():\n",
    "            if k=='value':\n",
    "                label.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=list(zip(text, category, subcat, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(d, columns=['text', 'category', 'subcategory', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effective Date: May 7, 2015 Kraft Site Privacy...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other Type</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noSelectedText</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Collection Mode</td>\n",
       "      <td>not-selected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collec</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Choice Scope</td>\n",
       "      <td>Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>register on our website or participate in our ...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Action First-Party</td>\n",
       "      <td>Collect on website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>personally-identifiable information, such as</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Personal Information Type</td>\n",
       "      <td>Generic personal information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Effective Date: May 7, 2015 Kraft Site Privacy...   \n",
       "1                                     noSelectedText   \n",
       "2                                             collec   \n",
       "3  register on our website or participate in our ...   \n",
       "4       personally-identifiable information, such as   \n",
       "\n",
       "                     category                subcategory  \\\n",
       "0                       Other                 Other Type   \n",
       "1  First Party Collection/Use            Collection Mode   \n",
       "2  First Party Collection/Use               Choice Scope   \n",
       "3  First Party Collection/Use         Action First-Party   \n",
       "4  First Party Collection/Use  Personal Information Type   \n",
       "\n",
       "                          label  \n",
       "0          Introductory/Generic  \n",
       "1                  not-selected  \n",
       "2                    Collection  \n",
       "3            Collect on website  \n",
       "4  Generic personal information  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cat_sub'] = data['category'] +'-'+ data['subcategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_sub</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data Retention-Personal Information Type</th>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Retention-Retention Period</th>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Retention-Retention Purpose</th>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Security-Security Measure</th>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do Not Track-Do Not Track policy</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use-Action First-Party</th>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use-Choice Scope</th>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use-Choice Type</th>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use-Collection Mode</th>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use-Does/Does Not</th>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use-Identifiability</th>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use-Personal Information Type</th>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use-Purpose</th>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use-User Type</th>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International and Specific Audiences-Audience Type</th>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other-Other Type</th>\n",
       "      <td>3548</td>\n",
       "      <td>3548</td>\n",
       "      <td>3548</td>\n",
       "      <td>3548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy Change-Change Type</th>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy Change-Notification Type</th>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy Change-User Choice</th>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection-Action Third Party</th>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection-Choice Scope</th>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection-Choice Type</th>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection-Does/Does Not</th>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection-Identifiability</th>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection-Personal Information Type</th>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection-Purpose</th>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection-Third Party Entity</th>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection-User Type</th>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Access, Edit and Deletion-Access Scope</th>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Access, Edit and Deletion-Access Type</th>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Access, Edit and Deletion-User Type</th>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Choice/Control-Choice Scope</th>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Choice/Control-Choice Type</th>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Choice/Control-Personal Information Type</th>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Choice/Control-Purpose</th>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Choice/Control-User Type</th>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "cat_sub                                                              \n",
       "Data Retention-Personal Information Type             370       370   \n",
       "Data Retention-Retention Period                      370       370   \n",
       "Data Retention-Retention Purpose                     370       370   \n",
       "Data Security-Security Measure                      1008      1008   \n",
       "Do Not Track-Do Not Track policy                      90        90   \n",
       "First Party Collection/Use-Action First-Party       8935      8935   \n",
       "First Party Collection/Use-Choice Scope             8935      8935   \n",
       "First Party Collection/Use-Choice Type              8935      8935   \n",
       "First Party Collection/Use-Collection Mode          8935      8935   \n",
       "First Party Collection/Use-Does/Does Not            8935      8935   \n",
       "First Party Collection/Use-Identifiability          8935      8935   \n",
       "First Party Collection/Use-Personal Information...  8935      8935   \n",
       "First Party Collection/Use-Purpose                  8935      8935   \n",
       "First Party Collection/Use-User Type                8935      8935   \n",
       "International and Specific Audiences-Audience Type   939       939   \n",
       "Other-Other Type                                    3548      3548   \n",
       "Policy Change-Change Type                            548       548   \n",
       "Policy Change-Notification Type                      548       548   \n",
       "Policy Change-User Choice                            548       548   \n",
       "Third Party Sharing/Collection-Action Third Party   5221      5221   \n",
       "Third Party Sharing/Collection-Choice Scope         5221      5221   \n",
       "Third Party Sharing/Collection-Choice Type          5221      5221   \n",
       "Third Party Sharing/Collection-Does/Does Not        5221      5221   \n",
       "Third Party Sharing/Collection-Identifiability      5221      5221   \n",
       "Third Party Sharing/Collection-Personal Informa...  5221      5221   \n",
       "Third Party Sharing/Collection-Purpose              5221      5221   \n",
       "Third Party Sharing/Collection-Third Party Entity   5221      5221   \n",
       "Third Party Sharing/Collection-User Type            5221      5221   \n",
       "User Access, Edit and Deletion-Access Scope          746       746   \n",
       "User Access, Edit and Deletion-Access Type           746       746   \n",
       "User Access, Edit and Deletion-User Type             746       746   \n",
       "User Choice/Control-Choice Scope                    1789      1789   \n",
       "User Choice/Control-Choice Type                     1789      1789   \n",
       "User Choice/Control-Personal Information Type       1789      1789   \n",
       "User Choice/Control-Purpose                         1789      1789   \n",
       "User Choice/Control-User Type                       1789      1789   \n",
       "\n",
       "                                                    subcategory  label  \n",
       "cat_sub                                                                 \n",
       "Data Retention-Personal Information Type                    370    370  \n",
       "Data Retention-Retention Period                             370    370  \n",
       "Data Retention-Retention Purpose                            370    370  \n",
       "Data Security-Security Measure                             1008   1008  \n",
       "Do Not Track-Do Not Track policy                             90     90  \n",
       "First Party Collection/Use-Action First-Party              8935   8935  \n",
       "First Party Collection/Use-Choice Scope                    8935   8935  \n",
       "First Party Collection/Use-Choice Type                     8935   8935  \n",
       "First Party Collection/Use-Collection Mode                 8935   8935  \n",
       "First Party Collection/Use-Does/Does Not                   8935   8935  \n",
       "First Party Collection/Use-Identifiability                 8935   8935  \n",
       "First Party Collection/Use-Personal Information...         8935   8935  \n",
       "First Party Collection/Use-Purpose                         8935   8935  \n",
       "First Party Collection/Use-User Type                       8935   8935  \n",
       "International and Specific Audiences-Audience Type          939    939  \n",
       "Other-Other Type                                           3548   3548  \n",
       "Policy Change-Change Type                                   548    548  \n",
       "Policy Change-Notification Type                             548    548  \n",
       "Policy Change-User Choice                                   548    548  \n",
       "Third Party Sharing/Collection-Action Third Party          5221   5221  \n",
       "Third Party Sharing/Collection-Choice Scope                5221   5221  \n",
       "Third Party Sharing/Collection-Choice Type                 5221   5221  \n",
       "Third Party Sharing/Collection-Does/Does Not               5221   5221  \n",
       "Third Party Sharing/Collection-Identifiability             5221   5221  \n",
       "Third Party Sharing/Collection-Personal Informa...         5221   5221  \n",
       "Third Party Sharing/Collection-Purpose                     5221   5221  \n",
       "Third Party Sharing/Collection-Third Party Entity          5221   5221  \n",
       "Third Party Sharing/Collection-User Type                   5221   5221  \n",
       "User Access, Edit and Deletion-Access Scope                 746    746  \n",
       "User Access, Edit and Deletion-Access Type                  746    746  \n",
       "User Access, Edit and Deletion-User Type                    746    746  \n",
       "User Choice/Control-Choice Scope                           1789   1789  \n",
       "User Choice/Control-Choice Type                            1789   1789  \n",
       "User Choice/Control-Personal Information Type              1789   1789  \n",
       "User Choice/Control-Purpose                                1789   1789  \n",
       "User Choice/Control-User Type                              1789   1789  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('cat_sub').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text           36\n",
       "category       36\n",
       "subcategory    36\n",
       "label          36\n",
       "cat_sub        36\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['category','subcategory']).nunique().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cat_sub_lab'] = data['category'] +'-'+ data['subcategory'] +'-'+ data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "data['text'] = data['text'].apply(lambda x : remove_punct(x.lower()))\n",
    "\n",
    "data = data[data['text']!='null']\n",
    "data = data[data['text']!='noselectedtext']\n",
    "data = data[data['text']!='']\n",
    "data = data[data['text']!=' ']\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "ds = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36717, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>label</th>\n",
       "      <th>cat_sub</th>\n",
       "      <th>cat_sub_lab</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data Retention</th>\n",
       "      <td>676</td>\n",
       "      <td>676</td>\n",
       "      <td>676</td>\n",
       "      <td>676</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Security</th>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do Not Track</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Party Collection/Use</th>\n",
       "      <td>15346</td>\n",
       "      <td>15346</td>\n",
       "      <td>15346</td>\n",
       "      <td>15346</td>\n",
       "      <td>15346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International and Specific Audiences</th>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>2759</td>\n",
       "      <td>2759</td>\n",
       "      <td>2759</td>\n",
       "      <td>2759</td>\n",
       "      <td>2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy Change</th>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Sharing/Collection</th>\n",
       "      <td>10655</td>\n",
       "      <td>10655</td>\n",
       "      <td>10655</td>\n",
       "      <td>10655</td>\n",
       "      <td>10655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Access, Edit and Deletion</th>\n",
       "      <td>1094</td>\n",
       "      <td>1094</td>\n",
       "      <td>1094</td>\n",
       "      <td>1094</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Choice/Control</th>\n",
       "      <td>3798</td>\n",
       "      <td>3798</td>\n",
       "      <td>3798</td>\n",
       "      <td>3798</td>\n",
       "      <td>3798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text  subcategory  label  cat_sub  \\\n",
       "category                                                                   \n",
       "Data Retention                          676          676    676      676   \n",
       "Data Security                           808          808    808      808   \n",
       "Do Not Track                             67           67     67       67   \n",
       "First Party Collection/Use            15346        15346  15346    15346   \n",
       "International and Specific Audiences    582          582    582      582   \n",
       "Other                                  2759         2759   2759     2759   \n",
       "Policy Change                           932          932    932      932   \n",
       "Third Party Sharing/Collection        10655        10655  10655    10655   \n",
       "User Access, Edit and Deletion         1094         1094   1094     1094   \n",
       "User Choice/Control                    3798         3798   3798     3798   \n",
       "\n",
       "                                      cat_sub_lab  \n",
       "category                                           \n",
       "Data Retention                                676  \n",
       "Data Security                                 808  \n",
       "Do Not Track                                   67  \n",
       "First Party Collection/Use                  15346  \n",
       "International and Specific Audiences          582  \n",
       "Other                                        2759  \n",
       "Policy Change                                 932  \n",
       "Third Party Sharing/Collection              10655  \n",
       "User Access, Edit and Deletion               1094  \n",
       "User Choice/Control                          3798  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.groupby('category').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.groupby(['category','subcategory']).count().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.groupby(['category','subcategory','label']).count().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ds['tokenized'] = ds['text'].apply(lambda x : re.split(' ', x))\n",
    "# ds['tokenized_text']=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    " \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v = Word2Vec(ds['tokenized'])\n",
    "# w2v.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-19 20:43:21,229 : INFO : loading Word2Vec object from word2vec.model\n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "2019-09-19 20:43:21,286 : INFO : loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "2019-09-19 20:43:21,287 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-09-19 20:43:21,290 : INFO : loading vocabulary recursively from word2vec.model.vocabulary.* with mmap=None\n",
      "2019-09-19 20:43:21,295 : INFO : loading trainables recursively from word2vec.model.trainables.* with mmap=None\n",
      "2019-09-19 20:43:21,296 : INFO : setting ignored attribute cum_table to None\n",
      "2019-09-19 20:43:21,298 : INFO : loaded word2vec.model\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encode = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {k: v.index for k, v in word_vectors.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_word(new_word, new_vector, new_index, embedding_matrix, word2id):\n",
    "    embedding_matrix = np.insert(embedding_matrix, [new_index], [new_vector], axis=0)\n",
    "    \n",
    "    word2id = {word: (index+1) if index >= new_index else index for word, index in word2id.items()}\n",
    "    word2id[new_word] = new_index\n",
    "    return embedding_matrix, word2id\n",
    "\n",
    "UNK_INDEX = 0\n",
    "UNK_TOKEN = 'UNK'\n",
    "\n",
    "embedding_matrix = word_vectors.vectors\n",
    "unk_vector = embedding_matrix.mean(0)\n",
    "embedding_matrix, word2id = add_new_word(UNK_TOKEN, unk_vector, UNK_INDEX, embedding_matrix, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3933"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3933, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.insert(embedding_matrix, len(embedding_matrix), [np.zeros((100,))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3934"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[3933].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data created. Percentage of unknown words: 7006.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36717,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_int_data(token_text, word2id):\n",
    "    x = []\n",
    "    unk_count = 0\n",
    "    for item in token_text:\n",
    "        temp=[]\n",
    "        x.append(temp)\n",
    "        for word in item:\n",
    "            if word in word2id:\n",
    "                temp.append(word2id.get(word))\n",
    "            else:\n",
    "                temp.append(UNK_INDEX)\n",
    "                unk_count += 1\n",
    "    print('Data created. Percentage of unknown words: %.3f' % (unk_count))\n",
    "    return np.array(x)\n",
    "\n",
    "x=get_int_data(ds.tokenized, word2id)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ds['enumerated_text']=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds['enumerated_text']=ds['enumerated_text'].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ds.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "ds['Do_Not_Track'] = ds['category'].apply(lambda x: 1 if x == 'Do Not Track' else 0)\n",
    "ds['Other'] = ds['category'].apply(lambda x: 1 if x == 'Other' else 0)\n",
    "ds['First_Party_Collection_Use'] = ds['category'].apply(lambda x: 1 if x == 'First Party Collection/Use' else 0)\n",
    "ds['Third_Party_Sharing_Collection'] = ds['category'].apply(lambda x: 1 if x == 'Third Party Sharing/Collection' else 0)\n",
    "ds['User_Choice_Control'] = ds['category'].apply(lambda x: 1 if x == 'User Choice/Control' else 0)\n",
    "ds['International_and_Specific_Audiences'] = ds['category'].apply(lambda x: 1 if x == 'International and Specific Audiences' else 0)\n",
    "ds['Data_Security'] = ds['category'].apply(lambda x: 1 if x == 'Data Security' else 0)\n",
    "ds['Policy_Change'] = ds['category'].apply(lambda x: 1 if x == 'Policy Change' else 0)\n",
    "ds['Data_Retention'] = ds['category'].apply(lambda x: 1 if x == 'Data Retention' else 0)\n",
    "ds['User_Access_Edit_and_Deletion'] = ds['category'].apply(lambda x: 1 if x == 'User Access, Edit and Deletion' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "2759\n",
      "15346\n",
      "10655\n",
      "3798\n",
      "582\n",
      "808\n",
      "932\n",
      "676\n",
      "1094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>label</th>\n",
       "      <th>cat_sub</th>\n",
       "      <th>cat_sub_lab</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>enumerated_text</th>\n",
       "      <th>Do_Not_Track</th>\n",
       "      <th>Other</th>\n",
       "      <th>First_Party_Collection_Use</th>\n",
       "      <th>Third_Party_Sharing_Collection</th>\n",
       "      <th>User_Choice_Control</th>\n",
       "      <th>International_and_Specific_Audiences</th>\n",
       "      <th>Data_Security</th>\n",
       "      <th>Policy_Change</th>\n",
       "      <th>Data_Retention</th>\n",
       "      <th>User_Access_Edit_and_Deletion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>effective date may 7 2015 kraft site privacy n...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other Type</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "      <td>Other-Other Type</td>\n",
       "      <td>Other-Other Type-Introductory/Generic</td>\n",
       "      <td>[effective, date, may, 7, 2015, kraft, site, p...</td>\n",
       "      <td>[553, 244, 11, 2150, 839, 1332, 35, 26, 139, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collec</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Choice Scope</td>\n",
       "      <td>Collection</td>\n",
       "      <td>First Party Collection/Use-Choice Scope</td>\n",
       "      <td>First Party Collection/Use-Choice Scope-Collec...</td>\n",
       "      <td>[collec]</td>\n",
       "      <td>[2151]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>register on our website or participate in our ...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Action First-Party</td>\n",
       "      <td>Collect on website</td>\n",
       "      <td>First Party Collection/Use-Action First-Party</td>\n",
       "      <td>First Party Collection/Use-Action First-Party-...</td>\n",
       "      <td>[register, on, our, website, or, participate, ...</td>\n",
       "      <td>[204, 19, 10, 52, 6, 212, 13, 10, 168, 3, 363]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>personallyidentifiable information such as</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Personal Information Type</td>\n",
       "      <td>Generic personal information</td>\n",
       "      <td>First Party Collection/Use-Personal Informatio...</td>\n",
       "      <td>First Party Collection/Use-Personal Informatio...</td>\n",
       "      <td>[personallyidentifiable, information, such, as]</td>\n",
       "      <td>[630, 5, 31, 23]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if you choose to register on our website or pa...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Choice Type</td>\n",
       "      <td>Opt-in</td>\n",
       "      <td>First Party Collection/Use-Choice Type</td>\n",
       "      <td>First Party Collection/Use-Choice Type-Opt-in</td>\n",
       "      <td>[if, you, choose, to, register, on, our, websi...</td>\n",
       "      <td>[32, 4, 105, 1, 204, 19, 10, 52, 6, 212, 13, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  effective date may 7 2015 kraft site privacy n...   \n",
       "1                                             collec   \n",
       "2  register on our website or participate in our ...   \n",
       "3         personallyidentifiable information such as   \n",
       "4  if you choose to register on our website or pa...   \n",
       "\n",
       "                     category                subcategory  \\\n",
       "0                       Other                 Other Type   \n",
       "1  First Party Collection/Use               Choice Scope   \n",
       "2  First Party Collection/Use         Action First-Party   \n",
       "3  First Party Collection/Use  Personal Information Type   \n",
       "4  First Party Collection/Use                Choice Type   \n",
       "\n",
       "                          label  \\\n",
       "0          Introductory/Generic   \n",
       "1                    Collection   \n",
       "2            Collect on website   \n",
       "3  Generic personal information   \n",
       "4                        Opt-in   \n",
       "\n",
       "                                             cat_sub  \\\n",
       "0                                   Other-Other Type   \n",
       "1            First Party Collection/Use-Choice Scope   \n",
       "2      First Party Collection/Use-Action First-Party   \n",
       "3  First Party Collection/Use-Personal Informatio...   \n",
       "4             First Party Collection/Use-Choice Type   \n",
       "\n",
       "                                         cat_sub_lab  \\\n",
       "0              Other-Other Type-Introductory/Generic   \n",
       "1  First Party Collection/Use-Choice Scope-Collec...   \n",
       "2  First Party Collection/Use-Action First-Party-...   \n",
       "3  First Party Collection/Use-Personal Informatio...   \n",
       "4      First Party Collection/Use-Choice Type-Opt-in   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [effective, date, may, 7, 2015, kraft, site, p...   \n",
       "1                                           [collec]   \n",
       "2  [register, on, our, website, or, participate, ...   \n",
       "3    [personallyidentifiable, information, such, as]   \n",
       "4  [if, you, choose, to, register, on, our, websi...   \n",
       "\n",
       "                                     enumerated_text  Do_Not_Track  Other  \\\n",
       "0  [553, 244, 11, 2150, 839, 1332, 35, 26, 139, 2...             0      1   \n",
       "1                                             [2151]             0      0   \n",
       "2     [204, 19, 10, 52, 6, 212, 13, 10, 168, 3, 363]             0      0   \n",
       "3                                   [630, 5, 31, 23]             0      0   \n",
       "4  [32, 4, 105, 1, 204, 19, 10, 52, 6, 212, 13, 1...             0      0   \n",
       "\n",
       "   First_Party_Collection_Use  Third_Party_Sharing_Collection  \\\n",
       "0                           0                               0   \n",
       "1                           1                               0   \n",
       "2                           1                               0   \n",
       "3                           1                               0   \n",
       "4                           1                               0   \n",
       "\n",
       "   User_Choice_Control  International_and_Specific_Audiences  Data_Security  \\\n",
       "0                    0                                     0              0   \n",
       "1                    0                                     0              0   \n",
       "2                    0                                     0              0   \n",
       "3                    0                                     0              0   \n",
       "4                    0                                     0              0   \n",
       "\n",
       "   Policy_Change  Data_Retention  User_Access_Edit_and_Deletion  \n",
       "0              0               0                              0  \n",
       "1              0               0                              0  \n",
       "2              0               0                              0  \n",
       "3              0               0                              0  \n",
       "4              0               0                              0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "print(ds['Do_Not_Track'].sum())\n",
    "print(ds['Other'].sum())\n",
    "print(ds['First_Party_Collection_Use'].sum())\n",
    "print(ds['Third_Party_Sharing_Collection'].sum())\n",
    "print(ds['User_Choice_Control'].sum())\n",
    "print(ds['International_and_Specific_Audiences'].sum())\n",
    "print(ds['Data_Security'].sum())\n",
    "print(ds['Policy_Change'].sum())\n",
    "print(ds['Data_Retention'].sum())\n",
    "print(ds['User_Access_Edit_and_Deletion'].sum())\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enumerated_text</th>\n",
       "      <th>Do_Not_Track</th>\n",
       "      <th>Other</th>\n",
       "      <th>First_Party_Collection_Use</th>\n",
       "      <th>Third_Party_Sharing_Collection</th>\n",
       "      <th>User_Choice_Control</th>\n",
       "      <th>International_and_Specific_Audiences</th>\n",
       "      <th>Data_Security</th>\n",
       "      <th>Policy_Change</th>\n",
       "      <th>Data_Retention</th>\n",
       "      <th>User_Access_Edit_and_Deletion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[553, 244, 11, 2150, 839, 1332, 35, 26, 139, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2151]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[204, 19, 10, 52, 6, 212, 13, 10, 168, 3, 363]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[630, 5, 31, 23]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 4, 105, 1, 204, 19, 10, 52, 6, 212, 13, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     enumerated_text  Do_Not_Track  Other  \\\n",
       "0  [553, 244, 11, 2150, 839, 1332, 35, 26, 139, 2...             0      1   \n",
       "1                                             [2151]             0      0   \n",
       "2     [204, 19, 10, 52, 6, 212, 13, 10, 168, 3, 363]             0      0   \n",
       "3                                   [630, 5, 31, 23]             0      0   \n",
       "4  [32, 4, 105, 1, 204, 19, 10, 52, 6, 212, 13, 1...             0      0   \n",
       "\n",
       "   First_Party_Collection_Use  Third_Party_Sharing_Collection  \\\n",
       "0                           0                               0   \n",
       "1                           1                               0   \n",
       "2                           1                               0   \n",
       "3                           1                               0   \n",
       "4                           1                               0   \n",
       "\n",
       "   User_Choice_Control  International_and_Specific_Audiences  Data_Security  \\\n",
       "0                    0                                     0              0   \n",
       "1                    0                                     0              0   \n",
       "2                    0                                     0              0   \n",
       "3                    0                                     0              0   \n",
       "4                    0                                     0              0   \n",
       "\n",
       "   Policy_Change  Data_Retention  User_Access_Edit_and_Deletion  \n",
       "0              0               0                              0  \n",
       "1              0               0                              0  \n",
       "2              0               0                              0  \n",
       "3              0               0                              0  \n",
       "4              0               0                              0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_df = ds[['enumerated_text','Do_Not_Track','Other','First_Party_Collection_Use','Third_Party_Sharing_Collection',\\\n",
    "                  'User_Choice_Control','International_and_Specific_Audiences','Data_Security','Policy_Change','Data_Retention',\\\n",
    "                 'User_Access_Edit_and_Deletion']]\n",
    "category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_length = max(category_df.enumerated_text.apply(lambda x: len(x)))\n",
    "padded_docs = pad_sequences(category_df.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Activation, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/5\n",
      "25701/25701 [==============================] - 18s 704us/step - loss: 1.9596 - acc: 0.9961 - val_loss: 0.2857 - val_acc: 0.9986\n",
      "Epoch 2/5\n",
      "25701/25701 [==============================] - 18s 694us/step - loss: 0.2804 - acc: 0.9966 - val_loss: 0.4047 - val_acc: 0.9949\n",
      "Epoch 3/5\n",
      "25701/25701 [==============================] - 18s 688us/step - loss: 0.1800 - acc: 0.9979 - val_loss: 0.1060 - val_acc: 0.9990\n",
      "Epoch 4/5\n",
      "25701/25701 [==============================] - 17s 661us/step - loss: 0.1491 - acc: 0.9983 - val_loss: 0.1327 - val_acc: 0.9984\n",
      "Epoch 5/5\n",
      "25701/25701 [==============================] - 17s 655us/step - loss: 0.1299 - acc: 0.9987 - val_loss: 0.0980 - val_acc: 0.9987\n",
      "[[25644     9]\n",
      " [    5    43]]\n",
      "0.86\n",
      "0.8958333333333334\n",
      "[[10991     6]\n",
      " [    8    11]]\n",
      "0.6111111111111113\n",
      "0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.Do_Not_Track, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 30.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.05)))\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=5, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('do_not_track.h5')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/5\n",
      "25701/25701 [==============================] - 15s 593us/step - loss: 9.0386 - acc: 0.9952 - val_loss: 0.0278 - val_acc: 0.9983\n",
      "Epoch 2/5\n",
      "25701/25701 [==============================] - 15s 573us/step - loss: 9.0308 - acc: 0.9981 - val_loss: 0.0278 - val_acc: 0.9983\n",
      "Epoch 3/5\n",
      "25701/25701 [==============================] - 15s 579us/step - loss: 9.0308 - acc: 0.9981 - val_loss: 0.0278 - val_acc: 0.9983\n",
      "Epoch 4/5\n",
      "25701/25701 [==============================] - 15s 579us/step - loss: 9.0308 - acc: 0.9981 - val_loss: 0.0278 - val_acc: 0.9983\n",
      "Epoch 5/5\n",
      "25701/25701 [==============================] - 3s 102us/step - loss: 9.0308 - acc: 0.9981 - val_loss: 0.0278 - val_acc: 0.9983\n",
      "[[25653     0]\n",
      " [   48     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "[[10997     0]\n",
      " [   19     0]]\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.Do_Not_Track, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 300.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=5, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('do_not_track1.h5')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 90s 3ms/step - loss: 1.2865 - acc: 0.8170 - val_loss: 0.6962 - val_acc: 0.8379\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 17s 681us/step - loss: 0.9249 - acc: 0.8566 - val_loss: 0.7760 - val_acc: 0.8095\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 21s 798us/step - loss: 0.8611 - acc: 0.8709 - val_loss: 0.6460 - val_acc: 0.8592\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 20s 782us/step - loss: 0.8717 - acc: 0.8830 - val_loss: 0.6931 - val_acc: 0.8773\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 17s 661us/step - loss: 0.8041 - acc: 0.8888 - val_loss: 0.6683 - val_acc: 0.8624\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 17s 649us/step - loss: 0.7522 - acc: 0.9008 - val_loss: 0.6500 - val_acc: 0.8670\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 17s 649us/step - loss: 0.8401 - acc: 0.9148 - val_loss: 0.7412 - val_acc: 0.8598\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 20s 789us/step - loss: 0.7696 - acc: 0.9155 - val_loss: 0.8155 - val_acc: 0.8660\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 20s 779us/step - loss: 0.6809 - acc: 0.9246 - val_loss: 0.6092 - val_acc: 0.8869\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 17s 651us/step - loss: 0.7179 - acc: 0.9213 - val_loss: 0.5927 - val_acc: 0.9129\n",
      "[[22494  1247]\n",
      " [   53  1907]]\n",
      "0.7457958545170121\n",
      "0.9729591836734693\n",
      "[[9448  769]\n",
      " [ 191  608]]\n",
      "0.5588235294117647\n",
      "0.7609511889862328\n"
     ]
    }
   ],
   "source": [
    "# Other Model\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.Other, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 10.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('other.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 17s 680us/step - loss: 3.5967 - acc: 0.4708 - val_loss: 1.2694 - val_acc: 0.4494\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 17s 658us/step - loss: 1.7244 - acc: 0.5048 - val_loss: 1.0670 - val_acc: 0.5519\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 18s 700us/step - loss: 1.6122 - acc: 0.5382 - val_loss: 1.1313 - val_acc: 0.5551\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 17s 650us/step - loss: 1.5410 - acc: 0.5681 - val_loss: 1.2711 - val_acc: 0.5655\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 17s 648us/step - loss: 1.4917 - acc: 0.5946 - val_loss: 0.9915 - val_acc: 0.6178\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 17s 674us/step - loss: 1.4483 - acc: 0.6176 - val_loss: 1.0093 - val_acc: 0.6255\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 17s 673us/step - loss: 1.3921 - acc: 0.6361 - val_loss: 0.9999 - val_acc: 0.6728\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 17s 650us/step - loss: 1.3789 - acc: 0.6515 - val_loss: 0.9217 - val_acc: 0.6795\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 18s 697us/step - loss: 1.3034 - acc: 0.6698 - val_loss: 0.9934 - val_acc: 0.6511\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 18s 682us/step - loss: 1.3514 - acc: 0.6803 - val_loss: 0.9435 - val_acc: 0.6777\n",
      "[[ 7630  7347]\n",
      " [  126 10598]]\n",
      "0.7393351703931076\n",
      "0.9882506527415144\n",
      "[[3053 3341]\n",
      " [ 209 4413]]\n",
      "0.7131544925662573\n",
      "0.9547814798788403\n"
     ]
    }
   ],
   "source": [
    "#  First Party Collection/Use Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.First_Party_Collection_Use, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 10.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('first_party_collection_use.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 18s 703us/step - loss: 1.8786 - acc: 0.7662 - val_loss: 0.9764 - val_acc: 0.8736\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 17s 668us/step - loss: 1.5957 - acc: 0.8093 - val_loss: 1.1598 - val_acc: 0.8464\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 20s 763us/step - loss: 1.5642 - acc: 0.8367 - val_loss: 0.8983 - val_acc: 0.8866\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 21s 808us/step - loss: 1.3356 - acc: 0.8602 - val_loss: 1.6610 - val_acc: 0.7780\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 15s 590us/step - loss: 1.3650 - acc: 0.8613 - val_loss: 0.9649 - val_acc: 0.8666\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 20s 774us/step - loss: 1.2653 - acc: 0.8716 - val_loss: 1.1556 - val_acc: 0.8653\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 21s 826us/step - loss: 1.0824 - acc: 0.8855 - val_loss: 0.9180 - val_acc: 0.8516\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 22s 853us/step - loss: 1.1768 - acc: 0.8922 - val_loss: 0.9362 - val_acc: 0.8711\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 21s 807us/step - loss: 1.2530 - acc: 0.8889 - val_loss: 0.8126 - val_acc: 0.8976\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 29s 1ms/step - loss: 1.0447 - acc: 0.9049 - val_loss: 0.9271 - val_acc: 0.8933\n",
      "[[22955  2262]\n",
      " [   23   461]]\n",
      "0.28749610227627065\n",
      "0.9524793388429752\n",
      "[[9722 1102]\n",
      " [  73  119]]\n",
      "0.16843595187544233\n",
      "0.6197916666666666\n"
     ]
    }
   ],
   "source": [
    "#  Data Retention Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.Data_Retention, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 40.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('data_retention.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 23s 880us/step - loss: 3.2660 - acc: 0.8501 - val_loss: 0.9611 - val_acc: 0.9023\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 20s 786us/step - loss: 1.1606 - acc: 0.9045 - val_loss: 1.0616 - val_acc: 0.8203\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 19s 751us/step - loss: 0.9385 - acc: 0.9226 - val_loss: 0.6411 - val_acc: 0.9461\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 20s 788us/step - loss: 0.8606 - acc: 0.9442 - val_loss: 0.6253 - val_acc: 0.9272\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 19s 754us/step - loss: 0.7057 - acc: 0.9499 - val_loss: 0.5148 - val_acc: 0.9713\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 21s 802us/step - loss: 0.8601 - acc: 0.9623 - val_loss: 0.5710 - val_acc: 0.9734\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 21s 814us/step - loss: 0.6402 - acc: 0.9645 - val_loss: 0.5171 - val_acc: 0.9580\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 20s 780us/step - loss: 0.6653 - acc: 0.9683 - val_loss: 0.4134 - val_acc: 0.9698\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 20s 788us/step - loss: 0.4466 - acc: 0.9745 - val_loss: 0.4376 - val_acc: 0.9607\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 21s 828us/step - loss: 0.4839 - acc: 0.9746 - val_loss: 0.5882 - val_acc: 0.9700\n",
      "[[24701   449]\n",
      " [   15   536]]\n",
      "0.6979166666666667\n",
      "0.9727767695099818\n",
      "[[10487   272]\n",
      " [   58   199]]\n",
      "0.5467032967032968\n",
      "0.77431906614786\n"
     ]
    }
   ],
   "source": [
    "#  Data Security Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.Data_Security, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 40.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(50, activation='tanh', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('data_security.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 19s 731us/step - loss: 1.9720 - acc: 0.8891 - val_loss: 1.1745 - val_acc: 0.9102\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 17s 672us/step - loss: 1.5172 - acc: 0.9191 - val_loss: 2.5771 - val_acc: 0.8617\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 18s 682us/step - loss: 1.9192 - acc: 0.9322 - val_loss: 2.6822 - val_acc: 0.9355\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 17s 651us/step - loss: 1.4754 - acc: 0.9508 - val_loss: 1.6216 - val_acc: 0.8824\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 17s 653us/step - loss: 1.2988 - acc: 0.9564 - val_loss: 0.9926 - val_acc: 0.9604\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 17s 653us/step - loss: 1.1108 - acc: 0.9611 - val_loss: 1.3079 - val_acc: 0.9261\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 17s 661us/step - loss: 0.6700 - acc: 0.9712 - val_loss: 1.0255 - val_acc: 0.9670\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 17s 653us/step - loss: 0.8668 - acc: 0.9718 - val_loss: 0.8146 - val_acc: 0.9573\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 17s 652us/step - loss: 1.1968 - acc: 0.9590 - val_loss: 0.6854 - val_acc: 0.9752\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 17s 655us/step - loss: 1.4068 - acc: 0.9712 - val_loss: 1.1710 - val_acc: 0.9786\n",
      "[[24972   334]\n",
      " [    6   389]]\n",
      "0.6958855098389981\n",
      "0.9848101265822785\n",
      "[[10632   197]\n",
      " [   39   148]]\n",
      "0.556390977443609\n",
      "0.7914438502673797\n"
     ]
    }
   ],
   "source": [
    "#  International and Specific Audiences Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.International_and_Specific_Audiences, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 50.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('internation_specific_audiences.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 18s 705us/step - loss: 1.8597 - acc: 0.9052 - val_loss: 1.0832 - val_acc: 0.9155\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 20s 778us/step - loss: 1.4710 - acc: 0.9274 - val_loss: 2.8183 - val_acc: 0.9447\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 18s 692us/step - loss: 1.3554 - acc: 0.9313 - val_loss: 1.2800 - val_acc: 0.9326\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 18s 705us/step - loss: 1.3387 - acc: 0.9432 - val_loss: 0.9766 - val_acc: 0.9138\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 17s 677us/step - loss: 1.6407 - acc: 0.9497 - val_loss: 1.2843 - val_acc: 0.9314\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 17s 676us/step - loss: 1.2290 - acc: 0.9512 - val_loss: 0.8610 - val_acc: 0.9594\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 19s 727us/step - loss: 0.8615 - acc: 0.9675 - val_loss: 0.7682 - val_acc: 0.9541\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 17s 656us/step - loss: 1.2388 - acc: 0.9674 - val_loss: 0.6592 - val_acc: 0.9728\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 17s 659us/step - loss: 1.1881 - acc: 0.9647 - val_loss: 1.1056 - val_acc: 0.9613\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 17s 656us/step - loss: 0.6819 - acc: 0.9763 - val_loss: 1.0628 - val_acc: 0.9414\n",
      "[[24014  1292]\n",
      " [    1   394]]\n",
      "0.3786641037962518\n",
      "0.9974683544303797\n",
      "[[10208   621]\n",
      " [   24   163]]\n",
      "0.33573635427394444\n",
      "0.8716577540106952\n"
     ]
    }
   ],
   "source": [
    "#  International and Specific Audiences Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.International_and_Specific_Audiences, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 45.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('internation_specific_audiences1.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 16s 623us/step - loss: 1.9759 - acc: 0.9334 - val_loss: 0.4251 - val_acc: 0.9247\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 15s 592us/step - loss: 0.2892 - acc: 0.9683 - val_loss: 0.1446 - val_acc: 0.9661\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 16s 605us/step - loss: 0.1596 - acc: 0.9776 - val_loss: 0.1194 - val_acc: 0.9677\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 18s 685us/step - loss: 0.1295 - acc: 0.9824 - val_loss: 0.1329 - val_acc: 0.9660\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 15s 592us/step - loss: 0.1053 - acc: 0.9848 - val_loss: 0.1193 - val_acc: 0.9698\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 15s 597us/step - loss: 0.0838 - acc: 0.9880 - val_loss: 0.1215 - val_acc: 0.9660\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 15s 578us/step - loss: 0.0681 - acc: 0.9900 - val_loss: 0.1017 - val_acc: 0.9733\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 15s 579us/step - loss: 0.0617 - acc: 0.9918 - val_loss: 0.0970 - val_acc: 0.9762\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 16s 612us/step - loss: 0.0670 - acc: 0.9913 - val_loss: 0.0801 - val_acc: 0.9836\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 16s 641us/step - loss: 0.0522 - acc: 0.9928 - val_loss: 0.0740 - val_acc: 0.9834\n",
      "[[24893   160]\n",
      " [    2   646]]\n",
      "0.8885832187070151\n",
      "0.9969135802469136\n",
      "[[10617   115]\n",
      " [   68   216]]\n",
      "0.7024390243902439\n",
      "0.7605633802816901\n"
     ]
    }
   ],
   "source": [
    "#  Policy Change Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.Policy_Change, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 25.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('policy_change.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 21s 804us/step - loss: 2.1168 - acc: 0.8995 - val_loss: 0.4736 - val_acc: 0.9139\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 15s 592us/step - loss: 0.3652 - acc: 0.9542 - val_loss: 0.2125 - val_acc: 0.9505\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 15s 597us/step - loss: 0.2067 - acc: 0.9704 - val_loss: 0.1493 - val_acc: 0.9611\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 15s 592us/step - loss: 0.1494 - acc: 0.9778 - val_loss: 0.1533 - val_acc: 0.9596\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 15s 593us/step - loss: 0.1089 - acc: 0.9845 - val_loss: 0.1076 - val_acc: 0.9746\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 15s 597us/step - loss: 0.0983 - acc: 0.9855 - val_loss: 0.1019 - val_acc: 0.9793\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 15s 590us/step - loss: 0.0909 - acc: 0.9869 - val_loss: 0.1328 - val_acc: 0.9739\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 15s 585us/step - loss: 0.0954 - acc: 0.9877 - val_loss: 0.0988 - val_acc: 0.9792\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 15s 590us/step - loss: 0.0686 - acc: 0.9904 - val_loss: 0.0820 - val_acc: 0.9818\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 15s 596us/step - loss: 0.0592 - acc: 0.9916 - val_loss: 0.0722 - val_acc: 0.9833\n",
      "[[24909   144]\n",
      " [    1   647]]\n",
      "0.8992355802640721\n",
      "0.9984567901234568\n",
      "[[10609   123]\n",
      " [   61   223]]\n",
      "0.7079365079365079\n",
      "0.7852112676056338\n"
     ]
    }
   ],
   "source": [
    "#  Policy Change Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.Policy_Change, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 40.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('policy_change1.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 16s 630us/step - loss: 2.0218 - acc: 0.3278 - val_loss: 1.1172 - val_acc: 0.3812\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 15s 592us/step - loss: 1.6558 - acc: 0.4413 - val_loss: 1.2028 - val_acc: 0.4286\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 15s 593us/step - loss: 1.4304 - acc: 0.5360 - val_loss: 0.9508 - val_acc: 0.5411\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 15s 584us/step - loss: 1.2506 - acc: 0.6167 - val_loss: 0.9378 - val_acc: 0.5754\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 16s 607us/step - loss: 1.1333 - acc: 0.6671 - val_loss: 0.9471 - val_acc: 0.6187\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 21s 833us/step - loss: 0.9833 - acc: 0.7176 - val_loss: 0.9494 - val_acc: 0.6481\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 23s 878us/step - loss: 0.8860 - acc: 0.7530 - val_loss: 0.9542 - val_acc: 0.6850\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 16s 620us/step - loss: 0.8157 - acc: 0.7787 - val_loss: 1.0478 - val_acc: 0.6713\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 15s 599us/step - loss: 0.7340 - acc: 0.8039 - val_loss: 0.9295 - val_acc: 0.7045\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 16s 611us/step - loss: 0.7100 - acc: 0.8156 - val_loss: 1.0695 - val_acc: 0.6886\n",
      "[[13343  4895]\n",
      " [    2  7461]]\n",
      "0.7529138705282808\n",
      "0.9997320112555272\n",
      "[[4891 2933]\n",
      " [ 497 2695]]\n",
      "0.6111111111111112\n",
      "0.8442982456140351\n"
     ]
    }
   ],
   "source": [
    "#  Third Party Sharing/Collection Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.Third_Party_Sharing_Collection, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 20}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('third_party_sharing_collection.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 19s 728us/step - loss: 2.8562 - acc: 0.8621 - val_loss: 0.7851 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 17s 665us/step - loss: 0.9813 - acc: 0.8976 - val_loss: 0.7551 - val_acc: 0.8628\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 17s 664us/step - loss: 0.8291 - acc: 0.9090 - val_loss: 0.5104 - val_acc: 0.9252\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 17s 673us/step - loss: 0.7138 - acc: 0.9149 - val_loss: 0.5092 - val_acc: 0.9231\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 17s 666us/step - loss: 0.6280 - acc: 0.9228 - val_loss: 0.4813 - val_acc: 0.9142\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 17s 662us/step - loss: 0.5866 - acc: 0.9295 - val_loss: 0.4273 - val_acc: 0.9037\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 18s 707us/step - loss: 0.5629 - acc: 0.9301 - val_loss: 0.6435 - val_acc: 0.9020\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 19s 720us/step - loss: 0.5376 - acc: 0.9366 - val_loss: 0.4109 - val_acc: 0.9305\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 18s 688us/step - loss: 0.4600 - acc: 0.9389 - val_loss: 0.3448 - val_acc: 0.9579\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 17s 669us/step - loss: 0.4475 - acc: 0.9430 - val_loss: 0.3568 - val_acc: 0.9167\n",
      "[[23247  1717]\n",
      " [   11   726]]\n",
      "0.45660377358490567\n",
      "0.9850746268656716\n",
      "[[9800  859]\n",
      " [  59  298]]\n",
      "0.393659180977543\n",
      "0.834733893557423\n"
     ]
    }
   ],
   "source": [
    "#  User Access, Edit and Deletion Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.User_Access_Edit_and_Deletion, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 20}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('user_access_edit_deletion.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 20s 789us/step - loss: 2.6534 - acc: 0.9083 - val_loss: 0.8942 - val_acc: 0.8509\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 19s 757us/step - loss: 0.8492 - acc: 0.9144 - val_loss: 0.4729 - val_acc: 0.9404\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 19s 756us/step - loss: 0.6887 - acc: 0.9270 - val_loss: 0.4210 - val_acc: 0.9454\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 19s 732us/step - loss: 0.5932 - acc: 0.9377 - val_loss: 0.3875 - val_acc: 0.9479\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 19s 748us/step - loss: 0.5423 - acc: 0.9412 - val_loss: 0.3680 - val_acc: 0.9242\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 19s 753us/step - loss: 0.5211 - acc: 0.9426 - val_loss: 0.3691 - val_acc: 0.9451\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 19s 743us/step - loss: 0.4991 - acc: 0.9449 - val_loss: 0.3734 - val_acc: 0.9317\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 80s 3ms/step - loss: 0.4264 - acc: 0.9464 - val_loss: 0.3227 - val_acc: 0.9510\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 17s 677us/step - loss: 0.4423 - acc: 0.9498 - val_loss: 0.3893 - val_acc: 0.9338\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 17s 656us/step - loss: 0.3986 - acc: 0.9526 - val_loss: 0.3104 - val_acc: 0.9500\n",
      "[[24047   917]\n",
      " [   58   679]]\n",
      "0.5820831547363908\n",
      "0.921302578018996\n",
      "[[10200   459]\n",
      " [   92   265]]\n",
      "0.49028677150786304\n",
      "0.742296918767507\n"
     ]
    }
   ],
   "source": [
    "#  User Access, Edit and Deletion Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.User_Access_Edit_and_Deletion, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 15.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('user_access_edit_deletion1.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 18s 704us/step - loss: 1.9797 - acc: 0.2736 - val_loss: 1.1754 - val_acc: 0.3076\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 17s 667us/step - loss: 1.5750 - acc: 0.4779 - val_loss: 0.8585 - val_acc: 0.5046\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 17s 664us/step - loss: 1.2851 - acc: 0.6154 - val_loss: 0.7822 - val_acc: 0.6421\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 17s 663us/step - loss: 1.0296 - acc: 0.7093 - val_loss: 0.6792 - val_acc: 0.6901\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 17s 661us/step - loss: 0.8420 - acc: 0.7692 - val_loss: 0.6833 - val_acc: 0.7297\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 18s 687us/step - loss: 0.7164 - acc: 0.8126 - val_loss: 0.6601 - val_acc: 0.7611\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 18s 702us/step - loss: 0.6123 - acc: 0.8393 - val_loss: 0.6809 - val_acc: 0.7712\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 18s 702us/step - loss: 0.5602 - acc: 0.8561 - val_loss: 0.6930 - val_acc: 0.7723\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 16s 604us/step - loss: 0.5288 - acc: 0.8638 - val_loss: 0.6536 - val_acc: 0.7907\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 313s 12ms/step - loss: 0.4546 - acc: 0.8825 - val_loss: 0.5956 - val_acc: 0.8184\n",
      "[[19996  3014]\n",
      " [    1  2690]]\n",
      "0.6408576533650983\n",
      "0.9996283909327388\n",
      "[[8235 1674]\n",
      " [ 326  781]]\n",
      "0.43851768669286917\n",
      "0.7055103884372177\n"
     ]
    }
   ],
   "source": [
    "#  User Choice/Control Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.User_Choice_Control, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 40.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('user_choice_control.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25701 samples, validate on 11016 samples\n",
      "Epoch 1/10\n",
      "25701/25701 [==============================] - 17s 657us/step - loss: 3.6737 - acc: 0.1501 - val_loss: 2.1342 - val_acc: 0.1993\n",
      "Epoch 2/10\n",
      "25701/25701 [==============================] - 14s 529us/step - loss: 3.1323 - acc: 0.2314 - val_loss: 2.4285 - val_acc: 0.2457\n",
      "Epoch 3/10\n",
      "25701/25701 [==============================] - 13s 519us/step - loss: 3.1131 - acc: 0.2954 - val_loss: 2.0253 - val_acc: 0.3233\n",
      "Epoch 4/10\n",
      "25701/25701 [==============================] - 13s 519us/step - loss: 2.8034 - acc: 0.3871 - val_loss: 1.7263 - val_acc: 0.4780\n",
      "Epoch 5/10\n",
      "25701/25701 [==============================] - 13s 517us/step - loss: 2.5890 - acc: 0.4751 - val_loss: 2.1495 - val_acc: 0.4223\n",
      "Epoch 6/10\n",
      "25701/25701 [==============================] - 13s 519us/step - loss: 2.6417 - acc: 0.5327 - val_loss: 1.9300 - val_acc: 0.4924\n",
      "Epoch 7/10\n",
      "25701/25701 [==============================] - 13s 516us/step - loss: 2.2864 - acc: 0.5876 - val_loss: 1.7025 - val_acc: 0.5593\n",
      "Epoch 8/10\n",
      "25701/25701 [==============================] - 13s 525us/step - loss: 2.4432 - acc: 0.6232 - val_loss: 2.1061 - val_acc: 0.5660\n",
      "Epoch 9/10\n",
      "25701/25701 [==============================] - 13s 510us/step - loss: 2.5110 - acc: 0.6478 - val_loss: 4.1055 - val_acc: 0.5547\n",
      "Epoch 10/10\n",
      "25701/25701 [==============================] - 13s 509us/step - loss: 2.1507 - acc: 0.6767 - val_loss: 1.4221 - val_acc: 0.7060\n",
      "[[16154  6856]\n",
      " [   14  2677]]\n",
      "0.437990837696335\n",
      "0.9947974730583427\n",
      "[[6832 3077]\n",
      " [ 162  945]]\n",
      "0.3684928836030415\n",
      "0.8536585365853658\n"
     ]
    }
   ],
   "source": [
    "#  User Choice/Control Model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, category_df.User_Choice_Control, test_size=0.3, random_state = 0)\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 70.}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=100,\\\n",
    "                  validation_data=(x_test, y_test),class_weight=class_weights)\n",
    "\n",
    "model.save('user_choice_control1.h5')\n",
    "\n",
    "print(confusion_matrix(y_train,model.predict_classes(x_train)))\n",
    "print(f1_score(y_train, model.predict_classes(x_train)))\n",
    "print(recall_score(y_train, model.predict_classes(x_train)))\n",
    "print(confusion_matrix(y_test,model.predict_classes(x_test)))\n",
    "print(f1_score(y_test, model.predict_classes(x_test)))\n",
    "print(recall_score(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
