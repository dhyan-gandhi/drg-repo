{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations=glob.glob('data/OPP-115/annotations/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_list=[]\n",
    "for file in annotations:\n",
    "    annotations_list.append(pd.read_csv(file, header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot=pd.concat(annotations_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot.columns = ['annotation_ID', 'batch_ID', 'annotator_ID', 'policy_ID', 'segment_ID','category_name',\n",
    "            'attribute_value_pairs','date','policy_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot['dict'] = annot.attribute_value_pairs.apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_ID</th>\n",
       "      <th>batch_ID</th>\n",
       "      <th>annotator_ID</th>\n",
       "      <th>policy_ID</th>\n",
       "      <th>segment_ID</th>\n",
       "      <th>category_name</th>\n",
       "      <th>attribute_value_pairs</th>\n",
       "      <th>date</th>\n",
       "      <th>policy_URL</th>\n",
       "      <th>dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13160</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>{\"Other Type\": {\"endIndexInSegment\": 575, \"sta...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Other Type': {'endIndexInSegment': 575, 'sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13161</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>1</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>{\"Collection Mode\": {\"endIndexInSegment\": -1, ...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Collection Mode': {'endIndexInSegment': -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13162</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>1</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>{\"Collection Mode\": {\"endIndexInSegment\": -1, ...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Collection Mode': {'endIndexInSegment': -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13163</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>1</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>{\"Collection Mode\": {\"endIndexInSegment\": -1, ...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Collection Mode': {'endIndexInSegment': -1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13164</td>\n",
       "      <td>test_category_labeling_highlight_fordham_aaaa</td>\n",
       "      <td>121</td>\n",
       "      <td>3828</td>\n",
       "      <td>1</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>{\"Collection Mode\": {\"endIndexInSegment\": -1, ...</td>\n",
       "      <td>5/7/15</td>\n",
       "      <td>http://www.kraftrecipes.com/about/privacynotic...</td>\n",
       "      <td>{'Collection Mode': {'endIndexInSegment': -1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation_ID                                       batch_ID  annotator_ID  \\\n",
       "0          13160  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "1          13161  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "2          13162  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "3          13163  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "4          13164  test_category_labeling_highlight_fordham_aaaa           121   \n",
       "\n",
       "   policy_ID  segment_ID               category_name  \\\n",
       "0       3828           0                       Other   \n",
       "1       3828           1  First Party Collection/Use   \n",
       "2       3828           1  First Party Collection/Use   \n",
       "3       3828           1  First Party Collection/Use   \n",
       "4       3828           1  First Party Collection/Use   \n",
       "\n",
       "                               attribute_value_pairs    date  \\\n",
       "0  {\"Other Type\": {\"endIndexInSegment\": 575, \"sta...  5/7/15   \n",
       "1  {\"Collection Mode\": {\"endIndexInSegment\": -1, ...  5/7/15   \n",
       "2  {\"Collection Mode\": {\"endIndexInSegment\": -1, ...  5/7/15   \n",
       "3  {\"Collection Mode\": {\"endIndexInSegment\": -1, ...  5/7/15   \n",
       "4  {\"Collection Mode\": {\"endIndexInSegment\": -1, ...  5/7/15   \n",
       "\n",
       "                                          policy_URL  \\\n",
       "0  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "1  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "2  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "3  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "4  http://www.kraftrecipes.com/about/privacynotic...   \n",
       "\n",
       "                                                dict  \n",
       "0  {'Other Type': {'endIndexInSegment': 575, 'sta...  \n",
       "1  {'Collection Mode': {'endIndexInSegment': -1, ...  \n",
       "2  {'Collection Mode': {'endIndexInSegment': -1, ...  \n",
       "3  {'Collection Mode': {'endIndexInSegment': -1, ...  \n",
       "4  {'Collection Mode': {'endIndexInSegment': -1, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in annot['dict']:\n",
    "    for key, value in x.items():\n",
    "        value.pop('endIndexInSegment', None)\n",
    "        value.pop('startIndexInSegment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[]\n",
    "category=[]\n",
    "subcat=[]\n",
    "label=[]\n",
    "counter=0\n",
    "for i,x in enumerate(annot['dict']):\n",
    "    for key, value in x.items():\n",
    "        subcat.append(key)\n",
    "        if value.get('selectedText')==None:\n",
    "            text.append('noSelectedText')\n",
    "        else:\n",
    "            text.append(value.get('selectedText'))  \n",
    "        category.append(annot['category_name'][i])\n",
    "        for k, v in value.items():\n",
    "            if k=='value':\n",
    "                label.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=list(zip(text, category, subcat, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(d, columns=['text', 'category', 'subcategory', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effective Date: May 7, 2015 Kraft Site Privacy...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other Type</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noSelectedText</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Collection Mode</td>\n",
       "      <td>not-selected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collec</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Choice Scope</td>\n",
       "      <td>Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>register on our website or participate in our ...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Action First-Party</td>\n",
       "      <td>Collect on website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>personally-identifiable information, such as</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Personal Information Type</td>\n",
       "      <td>Generic personal information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Effective Date: May 7, 2015 Kraft Site Privacy...   \n",
       "1                                     noSelectedText   \n",
       "2                                             collec   \n",
       "3  register on our website or participate in our ...   \n",
       "4       personally-identifiable information, such as   \n",
       "\n",
       "                     category                subcategory  \\\n",
       "0                       Other                 Other Type   \n",
       "1  First Party Collection/Use            Collection Mode   \n",
       "2  First Party Collection/Use               Choice Scope   \n",
       "3  First Party Collection/Use         Action First-Party   \n",
       "4  First Party Collection/Use  Personal Information Type   \n",
       "\n",
       "                          label  \n",
       "0          Introductory/Generic  \n",
       "1                  not-selected  \n",
       "2                    Collection  \n",
       "3            Collect on website  \n",
       "4  Generic personal information  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "data['text'] = data['text'].apply(lambda x : remove_punct(x.lower()))\n",
    "\n",
    "data = data[data['text']!='null']\n",
    "data = data[data['text']!='noselectedtext']\n",
    "data = data[data['text']!='']\n",
    "data = data[data['text']!=' ']\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "ds = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>effective date may 7 2015 kraft site privacy n...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other Type</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collec</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Choice Scope</td>\n",
       "      <td>Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>register on our website or participate in our ...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Action First-Party</td>\n",
       "      <td>Collect on website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>personallyidentifiable information such as</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Personal Information Type</td>\n",
       "      <td>Generic personal information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if you choose to register on our website or pa...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "      <td>Choice Type</td>\n",
       "      <td>Opt-in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  effective date may 7 2015 kraft site privacy n...   \n",
       "1                                             collec   \n",
       "2  register on our website or participate in our ...   \n",
       "3         personallyidentifiable information such as   \n",
       "4  if you choose to register on our website or pa...   \n",
       "\n",
       "                     category                subcategory  \\\n",
       "0                       Other                 Other Type   \n",
       "1  First Party Collection/Use               Choice Scope   \n",
       "2  First Party Collection/Use         Action First-Party   \n",
       "3  First Party Collection/Use  Personal Information Type   \n",
       "4  First Party Collection/Use                Choice Type   \n",
       "\n",
       "                          label  \n",
       "0          Introductory/Generic  \n",
       "1                    Collection  \n",
       "2            Collect on website  \n",
       "3  Generic personal information  \n",
       "4                        Opt-in  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ds['tokenized'] = ds['text'].apply(lambda x : re.split(' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    " \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-19 15:07:41,855 : INFO : collecting all words and their counts\n",
      "2019-09-19 15:07:41,859 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-19 15:07:41,981 : INFO : PROGRESS: at sentence #10000, processed 150297 words, keeping 3400 word types\n",
      "2019-09-19 15:07:42,116 : INFO : PROGRESS: at sentence #20000, processed 311668 words, keeping 5095 word types\n",
      "2019-09-19 15:07:42,359 : INFO : PROGRESS: at sentence #30000, processed 476465 words, keeping 6341 word types\n",
      "2019-09-19 15:07:42,450 : INFO : collected 7149 word types from a corpus of 596891 raw words and 36717 sentences\n",
      "2019-09-19 15:07:42,451 : INFO : Loading a fresh vocabulary\n",
      "2019-09-19 15:07:42,488 : INFO : min_count=5 retains 3932 unique words (55% of original 7149, drops 3217)\n",
      "2019-09-19 15:07:42,494 : INFO : min_count=5 leaves 589885 word corpus (98% of original 596891, drops 7006)\n",
      "2019-09-19 15:07:42,577 : INFO : deleting the raw counts dictionary of 7149 items\n",
      "2019-09-19 15:07:42,585 : INFO : sample=0.001 downsamples 58 most-common words\n",
      "2019-09-19 15:07:42,591 : INFO : downsampling leaves estimated 405586 word corpus (68.8% of prior 589885)\n",
      "2019-09-19 15:07:42,620 : INFO : estimated required memory for 3932 words and 100 dimensions: 5111600 bytes\n",
      "2019-09-19 15:07:42,622 : INFO : resetting layer weights\n",
      "2019-09-19 15:07:42,812 : INFO : training model with 3 workers on 3932 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-09-19 15:07:43,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 15:07:43,570 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 15:07:43,572 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 15:07:43,573 : INFO : EPOCH - 1 : training on 596891 raw words (405889 effective words) took 0.7s, 576282 effective words/s\n",
      "2019-09-19 15:07:44,440 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 15:07:44,485 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 15:07:44,488 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 15:07:44,489 : INFO : EPOCH - 2 : training on 596891 raw words (405376 effective words) took 0.9s, 448474 effective words/s\n",
      "2019-09-19 15:07:45,295 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 15:07:45,390 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 15:07:45,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 15:07:45,392 : INFO : EPOCH - 3 : training on 596891 raw words (405413 effective words) took 0.9s, 457553 effective words/s\n",
      "2019-09-19 15:07:46,336 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 15:07:46,349 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 15:07:46,361 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 15:07:46,361 : INFO : EPOCH - 4 : training on 596891 raw words (405251 effective words) took 0.9s, 438771 effective words/s\n",
      "2019-09-19 15:07:47,062 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 15:07:47,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 15:07:47,109 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 15:07:47,109 : INFO : EPOCH - 5 : training on 596891 raw words (405143 effective words) took 0.7s, 549672 effective words/s\n",
      "2019-09-19 15:07:47,111 : INFO : training on a 2984455 raw words (2027072 effective words) took 4.3s, 474444 effective words/s\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {k: v.index for k, v in word_vectors.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_word(new_word, new_vector, new_index, embedding_matrix, word2id):\n",
    "    embedding_matrix = np.insert(embedding_matrix, [new_index], [new_vector], axis=0)\n",
    "    \n",
    "    word2id = {word: (index+1) if index >= new_index else index for word, index in word2id.items()}\n",
    "    word2id[new_word] = new_index\n",
    "    return embedding_matrix, word2id\n",
    "\n",
    "UNK_INDEX = 0\n",
    "UNK_TOKEN = 'UNK'\n",
    "\n",
    "embedding_matrix = word_vectors.vectors\n",
    "unk_vector = embedding_matrix.mean(0)\n",
    "embedding_matrix, word2id = add_new_word(UNK_TOKEN, unk_vector, UNK_INDEX, embedding_matrix, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.insert(embedding_matrix, len(embedding_matrix), [np.zeros((100,))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data created. Percentage of unknown words: 7006.000\n"
     ]
    }
   ],
   "source": [
    "def get_int_data(token_text, word2id):\n",
    "    x = []\n",
    "    unk_count = 0\n",
    "    for item in token_text:\n",
    "        temp=[]\n",
    "        x.append(temp)\n",
    "        for word in item:\n",
    "            if word in word2id:\n",
    "                temp.append(word2id.get(word))\n",
    "            else:\n",
    "                temp.append(UNK_INDEX)\n",
    "                unk_count += 1\n",
    "    print('Data created. Percentage of unknown words: %.3f' % (unk_count))\n",
    "    return np.array(x)\n",
    "\n",
    "x=get_int_data(ds.tokenized, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ds['enumerated_text']=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>enumerated_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Data Retention</th>\n",
       "      <th>Personal Information Type</th>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retention Period</th>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retention Purpose</th>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Security</th>\n",
       "      <th>Security Measure</th>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do Not Track</th>\n",
       "      <th>Do Not Track policy</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">First Party Collection/Use</th>\n",
       "      <th>Action First-Party</th>\n",
       "      <td>2733</td>\n",
       "      <td>2733</td>\n",
       "      <td>2733</td>\n",
       "      <td>2733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Choice Scope</th>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Choice Type</th>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Collection Mode</th>\n",
       "      <td>1528</td>\n",
       "      <td>1528</td>\n",
       "      <td>1528</td>\n",
       "      <td>1528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does/Does Not</th>\n",
       "      <td>1308</td>\n",
       "      <td>1308</td>\n",
       "      <td>1308</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifiability</th>\n",
       "      <td>636</td>\n",
       "      <td>636</td>\n",
       "      <td>636</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Information Type</th>\n",
       "      <td>3119</td>\n",
       "      <td>3119</td>\n",
       "      <td>3119</td>\n",
       "      <td>3119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purpose</th>\n",
       "      <td>4214</td>\n",
       "      <td>4214</td>\n",
       "      <td>4214</td>\n",
       "      <td>4214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Type</th>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International and Specific Audiences</th>\n",
       "      <th>Audience Type</th>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <th>Other Type</th>\n",
       "      <td>2759</td>\n",
       "      <td>2759</td>\n",
       "      <td>2759</td>\n",
       "      <td>2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Policy Change</th>\n",
       "      <th>Change Type</th>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notification Type</th>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Choice</th>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">Third Party Sharing/Collection</th>\n",
       "      <th>Action Third Party</th>\n",
       "      <td>1889</td>\n",
       "      <td>1889</td>\n",
       "      <td>1889</td>\n",
       "      <td>1889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Choice Scope</th>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Choice Type</th>\n",
       "      <td>681</td>\n",
       "      <td>681</td>\n",
       "      <td>681</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does/Does Not</th>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identifiability</th>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Information Type</th>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purpose</th>\n",
       "      <td>2727</td>\n",
       "      <td>2727</td>\n",
       "      <td>2727</td>\n",
       "      <td>2727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Entity</th>\n",
       "      <td>2094</td>\n",
       "      <td>2094</td>\n",
       "      <td>2094</td>\n",
       "      <td>2094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Type</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">User Access, Edit and Deletion</th>\n",
       "      <th>Access Scope</th>\n",
       "      <td>421</td>\n",
       "      <td>421</td>\n",
       "      <td>421</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Access Type</th>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Type</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">User Choice/Control</th>\n",
       "      <th>Choice Scope</th>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Choice Type</th>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Information Type</th>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purpose</th>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Type</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                text  label  \\\n",
       "category                             subcategory                              \n",
       "Data Retention                       Personal Information Type   188    188   \n",
       "                                     Retention Period            234    234   \n",
       "                                     Retention Purpose           254    254   \n",
       "Data Security                        Security Measure            808    808   \n",
       "Do Not Track                         Do Not Track policy          67     67   \n",
       "First Party Collection/Use           Action First-Party         2733   2733   \n",
       "                                     Choice Scope                528    528   \n",
       "                                     Choice Type                 937    937   \n",
       "                                     Collection Mode            1528   1528   \n",
       "                                     Does/Does Not              1308   1308   \n",
       "                                     Identifiability             636    636   \n",
       "                                     Personal Information Type  3119   3119   \n",
       "                                     Purpose                    4214   4214   \n",
       "                                     User Type                   343    343   \n",
       "International and Specific Audiences Audience Type               582    582   \n",
       "Other                                Other Type                 2759   2759   \n",
       "Policy Change                        Change Type                 341    341   \n",
       "                                     Notification Type           403    403   \n",
       "                                     User Choice                 188    188   \n",
       "Third Party Sharing/Collection       Action Third Party         1889   1889   \n",
       "                                     Choice Scope                342    342   \n",
       "                                     Choice Type                 681    681   \n",
       "                                     Does/Does Not               937    937   \n",
       "                                     Identifiability             386    386   \n",
       "                                     Personal Information Type  1463   1463   \n",
       "                                     Purpose                    2727   2727   \n",
       "                                     Third Party Entity         2094   2094   \n",
       "                                     User Type                   136    136   \n",
       "User Access, Edit and Deletion       Access Scope                421    421   \n",
       "                                     Access Type                 514    514   \n",
       "                                     User Type                   159    159   \n",
       "User Choice/Control                  Choice Scope               1099   1099   \n",
       "                                     Choice Type                1262   1262   \n",
       "                                     Personal Information Type   492    492   \n",
       "                                     Purpose                     802    802   \n",
       "                                     User Type                   143    143   \n",
       "\n",
       "                                                                tokenized  \\\n",
       "category                             subcategory                            \n",
       "Data Retention                       Personal Information Type        188   \n",
       "                                     Retention Period                 234   \n",
       "                                     Retention Purpose                254   \n",
       "Data Security                        Security Measure                 808   \n",
       "Do Not Track                         Do Not Track policy               67   \n",
       "First Party Collection/Use           Action First-Party              2733   \n",
       "                                     Choice Scope                     528   \n",
       "                                     Choice Type                      937   \n",
       "                                     Collection Mode                 1528   \n",
       "                                     Does/Does Not                   1308   \n",
       "                                     Identifiability                  636   \n",
       "                                     Personal Information Type       3119   \n",
       "                                     Purpose                         4214   \n",
       "                                     User Type                        343   \n",
       "International and Specific Audiences Audience Type                    582   \n",
       "Other                                Other Type                      2759   \n",
       "Policy Change                        Change Type                      341   \n",
       "                                     Notification Type                403   \n",
       "                                     User Choice                      188   \n",
       "Third Party Sharing/Collection       Action Third Party              1889   \n",
       "                                     Choice Scope                     342   \n",
       "                                     Choice Type                      681   \n",
       "                                     Does/Does Not                    937   \n",
       "                                     Identifiability                  386   \n",
       "                                     Personal Information Type       1463   \n",
       "                                     Purpose                         2727   \n",
       "                                     Third Party Entity              2094   \n",
       "                                     User Type                        136   \n",
       "User Access, Edit and Deletion       Access Scope                     421   \n",
       "                                     Access Type                      514   \n",
       "                                     User Type                        159   \n",
       "User Choice/Control                  Choice Scope                    1099   \n",
       "                                     Choice Type                     1262   \n",
       "                                     Personal Information Type        492   \n",
       "                                     Purpose                          802   \n",
       "                                     User Type                        143   \n",
       "\n",
       "                                                                enumerated_text  \n",
       "category                             subcategory                                 \n",
       "Data Retention                       Personal Information Type              188  \n",
       "                                     Retention Period                       234  \n",
       "                                     Retention Purpose                      254  \n",
       "Data Security                        Security Measure                       808  \n",
       "Do Not Track                         Do Not Track policy                     67  \n",
       "First Party Collection/Use           Action First-Party                    2733  \n",
       "                                     Choice Scope                           528  \n",
       "                                     Choice Type                            937  \n",
       "                                     Collection Mode                       1528  \n",
       "                                     Does/Does Not                         1308  \n",
       "                                     Identifiability                        636  \n",
       "                                     Personal Information Type             3119  \n",
       "                                     Purpose                               4214  \n",
       "                                     User Type                              343  \n",
       "International and Specific Audiences Audience Type                          582  \n",
       "Other                                Other Type                            2759  \n",
       "Policy Change                        Change Type                            341  \n",
       "                                     Notification Type                      403  \n",
       "                                     User Choice                            188  \n",
       "Third Party Sharing/Collection       Action Third Party                    1889  \n",
       "                                     Choice Scope                           342  \n",
       "                                     Choice Type                            681  \n",
       "                                     Does/Does Not                          937  \n",
       "                                     Identifiability                        386  \n",
       "                                     Personal Information Type             1463  \n",
       "                                     Purpose                               2727  \n",
       "                                     Third Party Entity                    2094  \n",
       "                                     User Type                              136  \n",
       "User Access, Edit and Deletion       Access Scope                           421  \n",
       "                                     Access Type                            514  \n",
       "                                     User Type                              159  \n",
       "User Choice/Control                  Choice Scope                          1099  \n",
       "                                     Choice Type                           1262  \n",
       "                                     Personal Information Type              492  \n",
       "                                     Purpose                                802  \n",
       "                                     User Type                              143  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.groupby(['category','subcategory']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Retention_Personal_Information_Type = ds[(ds['category']=='Data Retention') & (ds['subcategory']=='Personal Information Type')]\n",
    "Data_Retention_Retention_Period = ds[(ds['category']=='Data Retention') & (ds['subcategory']=='Retention Period')]\n",
    "Data_Retention_Retention_Purpose = ds[(ds['category']=='Data Retention') & (ds['subcategory']=='Retention Purpose')]\n",
    "\n",
    "Data_Security_Security_Measure = ds[(ds['category']=='Data Security') & (ds['subcategory']=='Security Measure')]\n",
    "\n",
    "Do_Not_Track_Do_Not_Track_Policy = ds[(ds['category']=='Do Not Track') & (ds['subcategory']=='Do Not Track policy')]\n",
    "\n",
    "First_Party_Collection_Use_Action_First_Party = ds[(ds['category']=='First Party Collection/Use') & (ds['subcategory']=='Action First-Party')]\n",
    "First_Party_Collection_Use_Choice_Scope = ds[(ds['category']=='First Party Collection/Use') & (ds['subcategory']=='Choice Scope')]\n",
    "First_Party_Collection_Use_Choice_Type = ds[(ds['category']=='First Party Collection/Use') & (ds['subcategory']=='Choice Type')]\n",
    "First_Party_Collection_Use_Collection_Mode = ds[(ds['category']=='First Party Collection/Use') & (ds['subcategory']=='Collection Mode')]\n",
    "First_Party_Collection_Use_Does_Does_Not = ds[(ds['category']=='First Party Collection/Use') & (ds['subcategory']=='Does/Does Not')]\n",
    "First_Party_Collection_Use_Identifiability = ds[(ds['category']=='First Party Collection/Use') & (ds['subcategory']=='Identifiability')]\n",
    "First_Party_Collection_Use_Personal_Information_Type = ds[(ds['category']=='First Party Collection/Use') & (ds['subcategory']=='Personal Information Type')]\n",
    "First_Party_Collection_Use_Purpose = ds[(ds['category']=='First Party Collection/Use') & (ds['subcategory']=='Purpose')]\n",
    "First_Party_Collection_Use_User_Type = ds[(ds['category']=='First Party Collection/Use') & (ds['subcategory']=='User Type')]\n",
    "\n",
    "International_And_Specific_Audiences_Audience_Type = ds[(ds['category']=='International and Specific Audiences') & (ds['subcategory']=='Audience Type')]\n",
    "\n",
    "Other_Other_Type = ds[(ds['category']=='Other') & (ds['subcategory']=='Other Type')]\n",
    "\n",
    "Policy_Change_Change_Type = ds[(ds['category']=='Policy Change') & (ds['subcategory']=='Change Type')]\n",
    "Policy_Change_Notification_Type = ds[(ds['category']=='Policy Change') & (ds['subcategory']=='Notification Type')]\n",
    "Policy_Change_User_Choice = ds[(ds['category']=='Policy Change') & (ds['subcategory']=='User Choice')]\n",
    "\n",
    "Third_Party_Sharing_Collection_Action_Third_Party = ds[(ds['category']=='Third Party Sharing/Collection') & (ds['subcategory']=='Action Third Party')]\n",
    "Third_Party_Sharing_Collection_Choice_Scope = ds[(ds['category']=='Third Party Sharing/Collection') & (ds['subcategory']=='Choice Scope')]\n",
    "Third_Party_Sharing_Collection_Choice_Type = ds[(ds['category']=='Third Party Sharing/Collection') & (ds['subcategory']=='Choice Type')]\n",
    "Third_Party_Sharing_Collection_Does_Does_Not = ds[(ds['category']=='Third Party Sharing/Collection') & (ds['subcategory']=='Does/Does Not')]\n",
    "Third_Party_Sharing_Collection_Identifiability = ds[(ds['category']=='Third Party Sharing/Collection') & (ds['subcategory']=='Identifiability')]\n",
    "Third_Party_Sharing_Collection_Personal_Information_Type = ds[(ds['category']=='Third Party Sharing/Collection') & (ds['subcategory']=='Personal Information Type')]\n",
    "Third_Party_Sharing_Collection_Purpose = ds[(ds['category']=='Third Party Sharing/Collection') & (ds['subcategory']=='Purpose')]\n",
    "Third_Party_Sharing_Collection_Third_Party_Entity = ds[(ds['category']=='Third Party Sharing/Collection') & (ds['subcategory']=='Third Party Entity')]\n",
    "Third_Party_Sharing_Collection_User_Type = ds[(ds['category']=='Third Party Sharing/Collection') & (ds['subcategory']=='User Type')]\n",
    "\n",
    "User_Access_Edit_And_Deletion_Access_Scope = ds[(ds['category']=='User Access, Edit and Deletion') & (ds['subcategory']=='Access Scope')]\n",
    "User_Access_Edit_And_Deletion_Access_Type = ds[(ds['category']=='User Access, Edit and Deletion') & (ds['subcategory']=='Access Type')]\n",
    "User_Access_Edit_And_Deletion_User_Type = ds[(ds['category']=='User Access, Edit and Deletion') & (ds['subcategory']=='User Type')]\n",
    "\n",
    "User_Choice_Control_Choice_Scope = ds[(ds['category']=='User Choice/Control') & (ds['subcategory']=='Choice Scope')]\n",
    "User_Choice_Control_Choice_Type = ds[(ds['category']=='User Choice/Control') & (ds['subcategory']=='Choice Type')]\n",
    "User_Choice_Control_Personal_Information_Type = ds[(ds['category']=='User Choice/Control') & (ds['subcategory']=='Personal Information Type')]\n",
    "User_Choice_Control_Purpose = ds[(ds['category']=='User Choice/Control') & (ds['subcategory']=='Purpose')]\n",
    "User_Choice_Control_User_Type = ds[(ds['category']=='User Choice/Control') & (ds['subcategory']=='User Type')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Retention_Personal_Information_Type.reset_index(inplace=True, drop=True)\n",
    "Data_Retention_Retention_Period.reset_index(inplace=True, drop=True)\n",
    "Data_Retention_Retention_Purpose.reset_index(inplace=True, drop=True)\n",
    "\n",
    "Data_Security_Security_Measure.reset_index(inplace=True, drop=True)\n",
    "\n",
    "Do_Not_Track_Do_Not_Track_Policy.reset_index(inplace=True, drop=True)\n",
    "\n",
    "First_Party_Collection_Use_Action_First_Party.reset_index(inplace=True, drop=True)\n",
    "First_Party_Collection_Use_Choice_Scope.reset_index(inplace=True, drop=True)\n",
    "First_Party_Collection_Use_Choice_Type.reset_index(inplace=True, drop=True)\n",
    "First_Party_Collection_Use_Collection_Mode.reset_index(inplace=True, drop=True)\n",
    "First_Party_Collection_Use_Does_Does_Not.reset_index(inplace=True, drop=True)\n",
    "First_Party_Collection_Use_Identifiability.reset_index(inplace=True, drop=True)\n",
    "First_Party_Collection_Use_Personal_Information_Type.reset_index(inplace=True, drop=True)\n",
    "First_Party_Collection_Use_Purpose.reset_index(inplace=True, drop=True)\n",
    "First_Party_Collection_Use_User_Type.reset_index(inplace=True, drop=True)\n",
    "\n",
    "International_And_Specific_Audiences_Audience_Type.reset_index(inplace=True, drop=True)\n",
    "\n",
    "Other_Other_Type.reset_index(inplace=True, drop=True)\n",
    "\n",
    "Policy_Change_Change_Type.reset_index(inplace=True, drop=True)\n",
    "Policy_Change_Notification_Type.reset_index(inplace=True, drop=True)\n",
    "Policy_Change_User_Choice.reset_index(inplace=True, drop=True)\n",
    "\n",
    "Third_Party_Sharing_Collection_Third_Party_Entity.reset_index(inplace=True, drop=True)\n",
    "Third_Party_Sharing_Collection_Action_Third_Party.reset_index(inplace=True, drop=True)\n",
    "Third_Party_Sharing_Collection_Choice_Scope.reset_index(inplace=True, drop=True)\n",
    "Third_Party_Sharing_Collection_Choice_Type.reset_index(inplace=True, drop=True)\n",
    "Third_Party_Sharing_Collection_Does_Does_Not.reset_index(inplace=True, drop=True)\n",
    "Third_Party_Sharing_Collection_Identifiability.reset_index(inplace=True, drop=True)\n",
    "Third_Party_Sharing_Collection_Personal_Information_Type.reset_index(inplace=True, drop=True)\n",
    "Third_Party_Sharing_Collection_Purpose.reset_index(inplace=True, drop=True)\n",
    "Third_Party_Sharing_Collection_User_Type.reset_index(inplace=True, drop=True)\n",
    "\n",
    "User_Access_Edit_And_Deletion_Access_Scope.reset_index(inplace=True, drop=True)\n",
    "User_Access_Edit_And_Deletion_Access_Type.reset_index(inplace=True, drop=True)\n",
    "User_Access_Edit_And_Deletion_User_Type.reset_index(inplace=True, drop=True)\n",
    "\n",
    "User_Choice_Control_Choice_Scope.reset_index(inplace=True, drop=True)\n",
    "User_Choice_Control_Choice_Type.reset_index(inplace=True, drop=True)\n",
    "User_Choice_Control_Personal_Information_Type.reset_index(inplace=True, drop=True)\n",
    "User_Choice_Control_Purpose.reset_index(inplace=True, drop=True)\n",
    "User_Choice_Control_User_Type.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(ds.enumerated_text.apply(lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encode = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-09-19 15:07:55,133 : WARNING : From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2019-09-19 15:07:55,667 : WARNING : From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131 samples, validate on 57 samples\n",
      "Epoch 1/10\n",
      "131/131 [==============================] - 4s 29ms/step - loss: 2.7638 - acc: 0.0992 - val_loss: 2.5911 - val_acc: 0.3333\n",
      "Epoch 2/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 2.3835 - acc: 0.5115 - val_loss: 2.4067 - val_acc: 0.3333\n",
      "Epoch 3/10\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 2.0301 - acc: 0.5344 - val_loss: 2.2475 - val_acc: 0.2982\n",
      "Epoch 4/10\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 1.7409 - acc: 0.5725 - val_loss: 2.1729 - val_acc: 0.2807\n",
      "Epoch 5/10\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 1.5554 - acc: 0.5802 - val_loss: 2.1385 - val_acc: 0.3333\n",
      "Epoch 6/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 1.3989 - acc: 0.6718 - val_loss: 2.1363 - val_acc: 0.3509\n",
      "Epoch 7/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 1.2575 - acc: 0.7481 - val_loss: 2.0985 - val_acc: 0.3509\n",
      "Epoch 8/10\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 1.1445 - acc: 0.8015 - val_loss: 2.0386 - val_acc: 0.3684\n",
      "Epoch 9/10\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 1.0487 - acc: 0.8015 - val_loss: 1.9831 - val_acc: 0.4211\n",
      "Epoch 10/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.9732 - acc: 0.8092 - val_loss: 1.9633 - val_acc: 0.4035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 5, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 4, 2, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 3, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data_Retention_Personal_Information_Type\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Activation, Flatten\n",
    "\n",
    "\n",
    "padded_docs = pad_sequences(Data_Retention_Personal_Information_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Data_Retention_Personal_Information_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Data_Retention_Personal_Information_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = 'data_retention_personal_information_type_value_encode.sav'\n",
    "pickle.dump(encode, open(filename, 'wb'))\n",
    "\n",
    "model.save('data_retention_personal_information_type_value.h5')\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Retention-Retention Period\n",
    "\n",
    "padded_docs = pad_sequences(Data_Retention_Retention_Period.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Data_Retention_Retention_Period.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Data_Retention_Retention_Period.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "filename = 'data_retention_rentention_period_value_encode.sav'\n",
    "pickle.dump(encode, open(filename, 'wb'))\n",
    "\n",
    "model.save('data_retention_rentention_period_value.h5')\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Retention-Retention Purpose\n",
    "\n",
    "padded_docs = pad_sequences(Data_Retention_Retention_Purpose.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Data_Retention_Retention_Purpose.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Data_Retention_Retention_Purpose.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "filename = 'data_retention_rentention_period_value_encode.sav'\n",
    "pickle.dump(encode, open(filename, 'wb'))\n",
    "\n",
    "model.save('data_retention_rentention_period_value.h5')\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Security-Security Measure\n",
    "\n",
    "padded_docs = pad_sequences(Data_Security_Security_Measure.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Data_Security_Security_Measure.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Data_Security_Security_Measure.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Not Track-Do Not Track policy\n",
    "\n",
    "padded_docs = pad_sequences(Do_Not_Track_Do_Not_Track_Policy.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Do_Not_Track_Do_Not_Track_Policy.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Do_Not_Track_Do_Not_Track_Policy.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Party Collection/Use-Action First-Party\n",
    "\n",
    "padded_docs = pad_sequences(First_Party_Collection_Use_Action_First_Party.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(First_Party_Collection_Use_Action_First_Party.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, First_Party_Collection_Use_Action_First_Party.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Party Collection/Use-Choice Scope\n",
    "\n",
    "padded_docs = pad_sequences(First_Party_Collection_Use_Choice_Scope.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(First_Party_Collection_Use_Choice_Scope.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, First_Party_Collection_Use_Choice_Scope.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First_Party_Collection_Use_Choice_Type\n",
    "\n",
    "padded_docs = pad_sequences(First_Party_Collection_Use_Choice_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(First_Party_Collection_Use_Choice_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, First_Party_Collection_Use_Choice_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Party Collection/Use-Collection Mode\n",
    "\n",
    "padded_docs = pad_sequences(First_Party_Collection_Use_Collection_Mode.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(First_Party_Collection_Use_Collection_Mode.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, First_Party_Collection_Use_Collection_Mode.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Party Collection/Use-Does/Does Not\n",
    "\n",
    "padded_docs = pad_sequences(First_Party_Collection_Use_Does_Does_Not.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(First_Party_Collection_Use_Does_Does_Not.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, First_Party_Collection_Use_Does_Does_Not.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Party Collection/Use-Identifiability\n",
    "\n",
    "padded_docs = pad_sequences(First_Party_Collection_Use_Identifiability.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(First_Party_Collection_Use_Identifiability.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, First_Party_Collection_Use_Identifiability.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Party Collection/Use-Personal Information Type\n",
    "\n",
    "padded_docs = pad_sequences(First_Party_Collection_Use_Personal_Information_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(First_Party_Collection_Use_Personal_Information_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, First_Party_Collection_Use_Personal_Information_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Party Collection/Use-Purpose\n",
    "\n",
    "padded_docs = pad_sequences(First_Party_Collection_Use_Purpose.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(First_Party_Collection_Use_Purpose.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, First_Party_Collection_Use_Purpose.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Party Collection/Use-User Type\n",
    "\n",
    "padded_docs = pad_sequences(First_Party_Collection_Use_User_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(First_Party_Collection_Use_User_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, First_Party_Collection_Use_User_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#International and Specific Audiences-Audience Type\n",
    "\n",
    "padded_docs = pad_sequences(International_And_Specific_Audiences_Audience_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(International_And_Specific_Audiences_Audience_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, International_And_Specific_Audiences_Audience_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other-Other Type\n",
    "\n",
    "padded_docs = pad_sequences(Other_Other_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Other_Other_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Other_Other_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy Change-Change Type\n",
    "\n",
    "padded_docs = pad_sequences(Policy_Change_Change_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Policy_Change_Change_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Policy_Change_Change_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy Change-Notification Type\n",
    "\n",
    "padded_docs = pad_sequences(Policy_Change_Notification_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Policy_Change_Notification_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Policy_Change_Notification_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy Change-User Choice\n",
    "\n",
    "padded_docs = pad_sequences(Policy_Change_User_Choice.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Policy_Change_User_Choice.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Policy_Change_User_Choice.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Party Sharing/Collection-Action Third Party\n",
    "\n",
    "padded_docs = pad_sequences(Third_Party_Sharing_Collection_Action_Third_Party.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Third_Party_Sharing_Collection_Action_Third_Party.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Third_Party_Sharing_Collection_Action_Third_Party.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Party Sharing/Collection-Choice Scope\n",
    "\n",
    "padded_docs = pad_sequences(Third_Party_Sharing_Collection_Choice_Scope.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Third_Party_Sharing_Collection_Choice_Scope.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Third_Party_Sharing_Collection_Choice_Scope.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Party Sharing/Collection-Choice Type\n",
    "\n",
    "padded_docs = pad_sequences(Third_Party_Sharing_Collection_Choice_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Third_Party_Sharing_Collection_Choice_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Third_Party_Sharing_Collection_Choice_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Party Sharing/Collection-Does/Does Not\n",
    "\n",
    "padded_docs = pad_sequences(Third_Party_Sharing_Collection_Does_Does_Not.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Third_Party_Sharing_Collection_Does_Does_Not.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Third_Party_Sharing_Collection_Does_Does_Not.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Party Sharing/Collection-Identifiability\n",
    "\n",
    "padded_docs = pad_sequences(Third_Party_Sharing_Collection_Identifiability.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Third_Party_Sharing_Collection_Identifiability.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Third_Party_Sharing_Collection_Identifiability.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Party Sharing/Collection-Personal Information Type\n",
    "\n",
    "padded_docs = pad_sequences(Third_Party_Sharing_Collection_Personal_Information_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Third_Party_Sharing_Collection_Personal_Information_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Third_Party_Sharing_Collection_Personal_Information_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Party Sharing/Collection-Purpose\n",
    "\n",
    "padded_docs = pad_sequences(Third_Party_Sharing_Collection_Purpose.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Third_Party_Sharing_Collection_Purpose.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Third_Party_Sharing_Collection_Purpose.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Party Sharing/Collection-Third Party Entity\n",
    "\n",
    "padded_docs = pad_sequences(Third_Party_Sharing_Collection_Third_Party_Entity.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Third_Party_Sharing_Collection_Third_Party_Entity.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Third_Party_Sharing_Collection_Third_Party_Entity.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Party Sharing/Collection-User Type\n",
    "\n",
    "padded_docs = pad_sequences(Third_Party_Sharing_Collection_User_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(Third_Party_Sharing_Collection_User_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, Third_Party_Sharing_Collection_User_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Access, Edit and Deletion-Access Scope\n",
    "\n",
    "padded_docs = pad_sequences(User_Access_Edit_And_Deletion_Access_Scope.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(User_Access_Edit_And_Deletion_Access_Scope.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, User_Access_Edit_And_Deletion_Access_Scope.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Access, Edit and Deletion-Access Type\n",
    "\n",
    "padded_docs = pad_sequences(User_Access_Edit_And_Deletion_Access_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(User_Access_Edit_And_Deletion_Access_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, User_Access_Edit_And_Deletion_Access_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Access, Edit and Deletion-User Type\n",
    "\n",
    "padded_docs = pad_sequences(User_Access_Edit_And_Deletion_User_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(User_Access_Edit_And_Deletion_User_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, User_Access_Edit_And_Deletion_User_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Choice/Control-Choice Scope\n",
    "\n",
    "padded_docs = pad_sequences(User_Choice_Control_Choice_Scope.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(User_Choice_Control_Choice_Scope.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, User_Choice_Control_Choice_Scope.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Choice/Control-Choice Type\n",
    "\n",
    "padded_docs = pad_sequences(User_Choice_Control_Choice_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(User_Choice_Control_Choice_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, User_Choice_Control_Choice_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Choice/Control-Personal Information Type\n",
    "\n",
    "padded_docs = pad_sequences(User_Choice_Control_Personal_Information_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(User_Choice_Control_Personal_Information_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, User_Choice_Control_Personal_Information_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Choice/Control-Purpose\n",
    "\n",
    "padded_docs = pad_sequences(User_Choice_Control_Purpose.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(User_Choice_Control_Purpose.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, User_Choice_Control_Purpose.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Choice/Control-User Type\n",
    "\n",
    "padded_docs = pad_sequences(User_Choice_Control_User_Type.enumerated_text, maxlen=max_length, padding='post', value=(len(embedding_matrix)-1))\n",
    "\n",
    "onehot=encode.fit(np.array(User_Choice_Control_User_Type.label).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded_docs, User_Choice_Control_User_Type.label, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "onehotlabels_train = encode.transform(np.array(y_train).reshape(-1,1))\n",
    "onehotlabels_test = encode.transform(np.array(y_test).reshape(-1,1))\n",
    "\n",
    "\n",
    "vocab_length = len(embedding_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_length,\n",
    "                   output_dim=100,\n",
    "                   weights=[embedding_matrix],\n",
    "                   input_length=padded_docs.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(onehotlabels_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(x_train, onehotlabels_train, epochs=10, batch_size=100, validation_data=(x_test, onehotlabels_test))\n",
    "\n",
    "\n",
    "y_predict=model.predict_classes(x_test)\n",
    "y_test_label=np.argmax(onehotlabels_test, axis = 1)\n",
    "confusion_matrix(y_test_label,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
